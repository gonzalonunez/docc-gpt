# DoccGPT ðŸ§¹

![](https://github.com/gonzalonunez/docc-gpt/actions/workflows/build.yml/badge.svg)
[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fgonzalonunez%2Fdocc-gpt%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/gonzalonunez/docc-gpt)
[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fgonzalonunez%2Fdocc-gpt%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/gonzalonunez/docc-gpt)

DoccGPT is an experiment in self-documenting Swift code by leveraging [OpenAI](https://platform.openai.com/docs/api-reference/edits) and [DocC](https://developer.apple.com/documentation/docc), Apple's documentation compiler:

> The DocC documentation compiler converts Markdown-based text into rich documentation for Swift and Objective-C projects, and displays it right in the Xcode documentation window. You can also host this documentation on a website.

By pairing DoccGPT together with the wonderful [Swift Package Index](https://blog.swiftpackageindex.com/posts/auto-generating-auto-hosting-and-auto-updating-docc-documentation/), which compiles and hosts your documentation for you, you can come very close to fully automating the documentation of your codebase (not quite, but we'll get there, read the FAQ below). DoccGPT writes the documentation for you, or at least takes an initial pass at it, and the Swift Package Index takes care of compiling and hosting the generated documentation for you.

All of markup in both `/Sources/Example` and `/Sources/DoccGPT` was generated by running DoccGPT on itself:

```diff
+ /// Options for writing a GIF.
struct GifWritingOptions {

+  /// The duration of each frame in the GIF.
  var duration: TimeInterval

+  /// The scale of the GIF.
  var scale: CGFloat = 1

+  /// The looping behavior of the GIF.
  var gifLoop: GifLoop = .infinite

+  /// Whether to overwrite an existing file.
  var shouldOverwrite: Bool = true

+  /// The quality of service for the writing operation.
  var qos: DispatchQoS.QoSClass = .default

+  /// Whether to skip images that fail to encode.
  var skipsFailedImages: Bool = true
}
```

Depending on the model used, it is smart enough to document long and complex Swift code. An initial attempt used the `/edits` endpoint instead of `/completions` and `text-davinci-003` but it was only smart enough to document the simpler code in `/Example` and would not make any changes to `/DoccGPT`. That said, I'm sure we can still improve the quality of the comments. And there may still be sufficiently complex code that DoccGPT is unable to handle, I don't know. Any and all help improving DoccGPT is very much welcome!

## Basic usage

Run the package and give it a directory as well as your [OpenAI secret key](https://platform.openai.com/account/api-keys).

> **Warning**
> DoccGPT will attempt to rewrite the contents of every single `.swift` file in the directory that you feed it. And if you feed it a sufficiently long file it won't make it all the way to the end!

```bash
swift run docc-gpt <directory> --key <key>
```

```bash
ARGUMENTS:
  <directory>             The folder whose contents you want to document

OPTIONS:
  -k, --key <key>         Your secret API key for OpenAI
  -h, --help              Show help information.
```

## How it works

DoccGPT is a command-line tool written in Swift that iterates through all `.swift` files in a given directory and attempts to document your code using [DocC](https://developer.apple.com/documentation/docc) syntax:

> DocC syntax â€” called documentation markup â€” is a custom variant of Markdown that adds functionality for developer documentation-specific features, like cross-symbol linking, term-definition lists, code listings, and asides.

At the time of writing, the documentation markup is generated by feeding entire `.swift` files to `POST https://api.openai.com/v1/completions` and using the `text-davinci-003` model. The prompt given to the model can be found in `Prompt.swift`. I previously had a working version with the `/edits`, but OpenAI seems to have removed all compatible models at the time. That said, this works even better as its capable of documenting more complicated code. I have not tried using GPT-4 yet, which I'm sure is even more capable.

## FAQ

#### What's missing?

Number of tokens is an issue, it seems. I was unable to fully document `DoccGPTRunner.swift` because I ran out of tokens. The current token limit, at least the one that `text-davinci-003` has, is probably not viable for the average Swift file. For now I suppose the solution is to write less code, use GPT-4, or wait until GPT-5 ðŸ˜„

I also haven't figured out what to do about re-running the model on a file that has already been documented. In rare cases, it actually improves upon its initial choices. Most of the time, it'll just remove the final newline in the file. This can probably be fixed with better prompting.

Lastly, there is quite a bit of other basic CLI work needed to take this all of the way to a usable state, like exposing the ability to ignore certain files/subdirectories.

#### Would I use this in production?

Well, for what it's worth, you're sending all of your code up to OpenAI's servers, so probably not.

Assuming we address the privacy implications and the limitations described above, maybe? I probably wouldn't dare auto-commit anything in CI though. I would more likely run this once on a given codebase, perhaps a very large one that's not well-documented, and then maintain it myself from there. At best, maybe I would run it in CI on pushes to `master` and have it open PRs automatically.

That said, I don't think it's far-fetched at all to expect fully automated self-documenting codebases in the near-term future! My current first impressions are that a good prompt goes a long way and that there are huge performance differences between different models / APIs. I'm excited for a future where we can run powerful models locally.
